{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding up CDF in Python with Numba\n",
    "\n",
    "Saeed Amen - https://www.cuemacro.com - saeed@cuemacro.com\n",
    "\n",
    "In this notebook, we'll focus on speeding up the normal Cumulative Distribution Function in Python. This function is used often, for example in the Black-Scholes formula for pricing options. The normal CDF tends to be one of the slower arithmetic operations in the pricing.\n",
    "\n",
    "If we are only pricing a single option this probably doesn't matter. However, if we are using it in a loop (eg. for pricing many options, in a numerical solver etc.), speeding up this bottleneck could be very helpful indeed. We'll go through a few different variations of the CDF in Python to see how can speed it up, in particular using Numba. We'll be running benchmarks using `timeit` (obviously these will give different timings on other machines\n",
    "\n",
    "I've been using the FinancePy library a lot which can price options available from https://github.com/domokane/FinancePy (and made a few very small contributions to speeding up parts). We'll also be benchmarking the CDF function implemented in FinancePy later too.\n",
    "\n",
    "**If you are interested in speeding up your Python code, I run a workshop, which I can teach at your firm on \"Python, alternative data, natural language processing and large datasets\", part of which is about using Numba and other tools to speed up numerical calculations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Numba (http://numba.pydata.org/)?\n",
    "\n",
    "Numba understands many `numpy` functions and can speed them up, and it understands NumPy data structures like `narray` objects. It doesn't understand Pandas DataFrames, or indeed functions from scipy. Hence, when you need to use Numba with Pandas, you will need to rewrite you code to expose the underlying `narray` objects used to store the data in the DataFrame. On an experimental basis, Numba does support classes, but in general, I think it's easier to use with functions. \n",
    "\n",
    "Basically, Numba compiles the code at runtime using an LLVM, and this compilation can also be cached. I have tended to find it easier to use than alternatives like Cython and your code is still quite recognisable as \"Python\" (albeit with various additional decorators). One of the big no-nos in Python, is to use lots of tightly nested for loops. Typically, you should try to vectorize your calculations to get speedups with NumPy. However, \n",
    "\n",
    "You will also have to decorate your Python code to indicate to the LLVM that you want it to be compiled by Numba (or jitted). Ideally, your function will be speeded up most if there is no need to interact with the Python interpreter when running it. In these cases, you can try decorating your code with the `njit` keyword. Numba, will tell you if needs to interact with the Python interpreter by throwing an error (in which case you will need to use the `jit` keyword)! In some cases, you may also need to specify the types of the inputs and outputs in the decorator. There are all sorts of other flags, such as \n",
    "* `fastmath` (speeds up maths calculations but might be accurate to fewer decimal places) \n",
    "* `cache` (which will cache the compiled code).\n",
    "* `vectorize` that can be used to run the same computation across many elements of a vector\n",
    "* `parallel` that can be used to parallelize for loops\n",
    "    \n",
    "Numba lets you target the CPU or GPU. For GPU, you'll need to rewrite your code more, usually in a CUDA-like way, and you'll need to understand how a GPU works properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scipy\n",
    "\n",
    "Typically, when calculating the normal CDF, one of the most common ways is to use scipy, an in particular to run `scipy.stats.norm.cdf`. For our use case we shall assume that our input `n` is always `0.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T12:55:01.788086Z",
     "start_time": "2021-01-02T12:55:01.780086Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "n = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking `scipy.stats.norm.cdf`\n",
    "\n",
    "If we run a benchmark of this function it takes around 60 µs on my machine when using `timeit`, which runs it many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T12:41:05.224869Z",
     "start_time": "2021-01-02T12:41:00.091870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.2 µs ± 858 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "norm.cdf(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking `scipy.special.ndtr`\n",
    "\n",
    "If we explore the code for scipy on GitHub, given it's all open source, we find that underneath, it actually calls the `scipy.special.ndtr` function. Does calling this function directly help in terms of speeding up our calculation? Amazingly, simply calling this lower level function makes our code run in around 600ns, which is a massive speedup! Simply by doing a lower level call, we have speeded up our calculation by 100x!\n",
    "\n",
    "This isn't a unique situation. Very often for example, when using Pandas, underneath a lot of the arithmetic operations are done using NumPy. By calling the NumPy methods directly we can speed up our calculation in many instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T12:48:20.197536Z",
     "start_time": "2021-01-02T12:48:20.194536Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import ndtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T12:41:10.339868Z",
     "start_time": "2021-01-02T12:41:05.226869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629 ns ± 5.06 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "ndtr(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T12:08:33.405597Z",
     "start_time": "2021-01-02T12:08:33.402598Z"
    }
   },
   "source": [
    "## Rewriting CDF (with and without Numba)\n",
    "\n",
    "### Benchmarking `scipy.special.ndtr` converted into Python\n",
    "\n",
    "If we go through the source code of ndtr, we find that underneath it is actually C code, and these can be called from Cython code (see https://docs.scipy.org/doc/scipy/reference/special.cython_special.html). What if we try to rewrite this code as Python, and try to call it? We'll have to take out a bunch of curly brackets and make the code Pythonic. Thankfully it's sufficiently simple code that it isn't too difficult. There are Python equivalents for `fabs`, `erf` and `erfc` in the Python `math` module, which we can use after importing (note, `erf` and `erfc` are actually also included in the below C code, so we could have converted these if we'd wanted to).\n",
    "\n",
    "The C code can be found at https://github.com/scipy/scipy/blob/master/scipy/special/cephes/ndtr.c\n",
    "\n",
    "```\n",
    "double ndtr(double a)\n",
    "{\n",
    "    double x, y, z;\n",
    "\n",
    "    if (cephes_isnan(a)) {\n",
    "\tsf_error(\"ndtr\", SF_ERROR_DOMAIN, NULL);\n",
    "\treturn (NPY_NAN);\n",
    "    }\n",
    "\n",
    "    x = a * NPY_SQRT1_2;\n",
    "    z = fabs(x);\n",
    "\n",
    "    if (z < NPY_SQRT1_2)\n",
    "\ty = 0.5 + 0.5 * erf(x);\n",
    "\n",
    "    else {\n",
    "\ty = 0.5 * erfc(z);\n",
    "\n",
    "\tif (x > 0)\n",
    "\t    y = 1.0 - y;\n",
    "    }\n",
    "\n",
    "    return (y);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T15:28:35.707638Z",
     "start_time": "2021-01-02T15:28:35.702644Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from math import fabs, erf, erfc, exp\n",
    "\n",
    "NPY_SQRT1_2 = 1.0/ np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T13:23:58.737875Z",
     "start_time": "2021-01-02T13:23:58.719875Z"
    }
   },
   "outputs": [],
   "source": [
    "def ndtr_python(a):\n",
    "\n",
    "    if (np.isnan(a)):\n",
    "        return np.nan\n",
    "\n",
    "    x = a * NPY_SQRT1_2;\n",
    "    z = fabs(x)\n",
    "\n",
    "    if (z < NPY_SQRT1_2):\n",
    "        y = 0.5 + 0.5 * erf(x)\n",
    "\n",
    "    else:\n",
    "        y = 0.5 * erfc(z)\n",
    "\n",
    "        if (x > 0):\n",
    "            y = 1.0 - y\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we benchmark it we find it's slower, at around 1.4 µs. This probably isn't surprising given that `ndtr` was calling lower level C code underneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T13:24:10.680454Z",
     "start_time": "2021-01-02T13:23:59.416454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39 µs ± 14.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "ndtr_python(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a Numba-ized version of `ndtr`, because the code is sufficiently simple, by adding the `njit` decorator at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T13:24:10.695457Z",
     "start_time": "2021-01-02T13:24:10.682457Z"
    }
   },
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T15:30:25.876194Z",
     "start_time": "2021-01-02T15:30:25.855274Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def ndtr_numba(a):\n",
    "\n",
    "    if (np.isnan(a)):\n",
    "        return np.nan\n",
    "\n",
    "    x = a * NPY_SQRT1_2;\n",
    "    z = fabs(x)\n",
    "\n",
    "    if (z < NPY_SQRT1_2):\n",
    "        y = 0.5 + 0.5 * erf(x)\n",
    "\n",
    "    else:\n",
    "        y = 0.5 * erfc(z)\n",
    "\n",
    "        if (x > 0):\n",
    "            y = 1.0 - y\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Numba yields a time of around 170ns, much quicker, than the pure Python implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T15:30:40.699985Z",
     "start_time": "2021-01-02T15:30:26.711753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 ns ± 0.478 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "ndtr_numba(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with FinancePy's CDF\n",
    "\n",
    "In the above cases, we were using the same algorithm for computing the CDF, just executing it in different ways. Here, we shall benchmark the performance of the CDF algorithm in FinancePy which is different. It is a fast approximation of the CDF good to around 6 decimal places. \n",
    "\n",
    "### Benchmarking FinancePy's CDF (with and without Numba)\n",
    "\n",
    "If we benchmark FinancePy's CDF function `N(.)` (see https://github.com/domokane/FinancePy/blob/master/financepy/finutils/FinMath.py). We shall show the performance without the code being Numba-ized (or jitted) and with the jitted code actually used in the FinancePy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T13:27:06.242588Z",
     "start_time": "2021-01-02T13:27:06.236588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on code by Dominic O'Kane\n",
    "# Copyright (C) 2018, 2019, 2020 Dominic O'Kane\n",
    "\n",
    "def N_python(x):\n",
    "    ''' Fast Normal CDF function based on Hull OFAODS  4th Edition Page 252. \n",
    "    This function is accurate to 6 decimal places. '''\n",
    "\n",
    "    a1 = 0.319381530\n",
    "    a2 = -0.356563782\n",
    "    a3 = 1.781477937\n",
    "    a4 = -1.821255978\n",
    "    a5 = 1.330274429\n",
    "    g = 0.2316419\n",
    "\n",
    "    k = 1.0 / (1.0 + g * fabs(x))\n",
    "    k2 = k * k\n",
    "    k3 = k2 * k\n",
    "    k4 = k3 * k\n",
    "    k5 = k4 * k\n",
    "\n",
    "    if x >= 0.0:\n",
    "        c = (a1 * k + a2 * k2 + a3 * k3 + a4 * k4 + a5 * k5)\n",
    "        phi = 1.0 - c * exp(-x*x/2.0) * NPY_SQRT1_2\n",
    "    else:\n",
    "        phi = 1.0 - N(-x)\n",
    "\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pure Python function `N_python` runs in around 720 ns, quicker than `ndtr_python` but slower than the jitted `ndtr_numba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T13:24:30.601986Z",
     "start_time": "2021-01-02T13:24:24.723990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722 ns ± 5.31 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "N_python(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now import the jitted `N(.)` function which is identical to the above, but it also has the `njit` declaration at the top. We find it is even faster than our jitted `ndtr_numba` function at close to 150ns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T13:24:30.616988Z",
     "start_time": "2021-01-02T13:24:30.603989Z"
    }
   },
   "outputs": [],
   "source": [
    "from financepy.finutils.FinMath import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T13:24:42.601987Z",
     "start_time": "2021-01-02T13:24:30.618988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 ns ± 0.929 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "N(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final check\n",
    "\n",
    "Just as a final check, let's see if all the outputs are similar! They are, to 8 decimal places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T13:24:42.616988Z",
     "start_time": "2021-01-02T13:24:42.603988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6914624612740131\n",
      "0.6914624612740131\n",
      "0.691462461274013\n",
      "0.6914624612740131\n",
      "0.6914624677873249\n",
      "0.6914624677873249\n"
     ]
    }
   ],
   "source": [
    "print(norm.cdf(n))\n",
    "print(ndtr(n))\n",
    "print(ndtr_python(n))\n",
    "print(ndtr_numba(n))\n",
    "print(N_python(n))\n",
    "print(N(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have seen that it is possible to speed up the CDF considerably, by using lower level calls in SciPy, and later translating the code into Python and then jitting it. We also compared the speed to FinancePy (both pure Python and jitted), which uses a different CDF algorithm.\n",
    "\n",
    "Here are some generalized steps that I would recommend to use when you find a bottleneck in your Python based numerical code:\n",
    "\n",
    "* Try to use a lower level function to access the same calculation\n",
    "* Translate the lower level function (if it's in C) to Python\n",
    "* More broadly if we want to jit the code, we:\n",
    "    * may use NumPy functions (but can't use Pandas for example)\n",
    "    * need to avoid more complicated Python structures/calls (so can use `njit` flag)\n",
    "* Once you are happy with your \"simplified\" Python code, we then need to jit it\n",
    "* Apply Numba decorator to jit the code\n",
    "    * with types if necessary\n",
    "    * add any additional flags\n",
    "* It is easier to debug non-jitted code, so you might need to add/remove the Numba decorator when debugging\n",
    "\n",
    "Should you try to jit all code? Probably not, because it can take time to rewrite (depending on how complicated you code is, and how much abstraction there is in your code). In many cases, it won't be necessary to jit your code, but where a particular part of code is a bottleneck, it might be worth spending the time to do rewrite it in Numba/jit it.\n",
    "\n",
    "Is this stuff *easy*, no not really, but once you get experience in doing this sort of thing, you can know what to look for when speeding up your Python code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
